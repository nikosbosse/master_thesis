<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Model aggregation | index.split</title>
  <meta name="description" content="This thesis, titled ‘Evaluation and Aggregation of Covid-19 death forecasts in the United States’ was submitted as a master thesis in Applied Statistics at the Universität Göttingen in September 2020." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Model aggregation | index.split" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="logo_university.png" />
  <meta property="og:description" content="This thesis, titled ‘Evaluation and Aggregation of Covid-19 death forecasts in the United States’ was submitted as a master thesis in Applied Statistics at the Universität Göttingen in September 2020." />
  <meta name="github-repo" content="nikosbosse/master_thesis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Model aggregation | index.split" />
  
  <meta name="twitter:description" content="This thesis, titled ‘Evaluation and Aggregation of Covid-19 death forecasts in the United States’ was submitted as a master thesis in Applied Statistics at the Universität Göttingen in September 2020." />
  <meta name="twitter:image" content="logo_university.png" />

<meta name="author" content="Nikos Bosse" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="evaluation.html"/>
<link rel="next" href="background-data.html"/>
<script src="libs/header-attrs-2.3/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Evaluation and Aggregation of Covid-19 Death Forecasts in the United States</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="ackowldedgements.html"><a href="ackowldedgements.html"><i class="fa fa-check"></i>Ackowldedgements</a></li>
<li class="chapter" data-level="" data-path="abbreviations.html"><a href="abbreviations.html"><i class="fa fa-check"></i>Abbreviations</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="evaluation.html"><a href="evaluation.html"><i class="fa fa-check"></i><b>2</b> Forecasting and evaluation</a>
<ul>
<li class="chapter" data-level="2.1" data-path="evaluation.html"><a href="evaluation.html#forecast-types"><i class="fa fa-check"></i><b>2.1</b> An overview of differenct forecast types</a></li>
<li class="chapter" data-level="2.2" data-path="evaluation.html"><a href="evaluation.html#the-forecasting-paradigm"><i class="fa fa-check"></i><b>2.2</b> The forecasting paradigm</a></li>
<li class="chapter" data-level="2.3" data-path="evaluation.html"><a href="evaluation.html#assessing-calibration"><i class="fa fa-check"></i><b>2.3</b> Assessing calibration</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="evaluation.html"><a href="evaluation.html#calibration-and-bias"><i class="fa fa-check"></i><b>2.3.1</b> Calibration and bias</a></li>
<li class="chapter" data-level="2.3.2" data-path="evaluation.html"><a href="evaluation.html#calibration-and-empirical-coverage"><i class="fa fa-check"></i><b>2.3.2</b> Calibration and empirical coverage</a></li>
<li class="chapter" data-level="2.3.3" data-path="evaluation.html"><a href="evaluation.html#calibration-and-the-probability-integral-transform"><i class="fa fa-check"></i><b>2.3.3</b> Calibration and the probability integral transform</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="evaluation.html"><a href="evaluation.html#assessing-sharpness"><i class="fa fa-check"></i><b>2.4</b> Assessing sharpness</a></li>
<li class="chapter" data-level="2.5" data-path="evaluation.html"><a href="evaluation.html#proper-scoring-rules"><i class="fa fa-check"></i><b>2.5</b> Proper scoring rules</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="evaluation.html"><a href="evaluation.html#log-score"><i class="fa fa-check"></i><b>2.5.1</b> Log Score</a></li>
<li class="chapter" data-level="2.5.2" data-path="evaluation.html"><a href="evaluation.html#continuous-ranked-probability-score"><i class="fa fa-check"></i><b>2.5.2</b> (Continuous) Ranked Probability Score</a></li>
<li class="chapter" data-level="2.5.3" data-path="evaluation.html"><a href="evaluation.html#interval-score"><i class="fa fa-check"></i><b>2.5.3</b> Interval score</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="evaluation.html"><a href="evaluation.html#a-proposed-evaluation-framework"><i class="fa fa-check"></i><b>2.6</b> A proposed evaluation framework</a></li>
<li class="chapter" data-level="2.7" data-path="evaluation.html"><a href="evaluation.html#the-scoringutils-package"><i class="fa fa-check"></i><b>2.7</b> The scoringutils package</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="model-aggregation.html"><a href="model-aggregation.html"><i class="fa fa-check"></i><b>3</b> Model aggregation</a>
<ul>
<li class="chapter" data-level="3.1" data-path="model-aggregation.html"><a href="model-aggregation.html#theoretical-motivation"><i class="fa fa-check"></i><b>3.1</b> Theoretical motivation</a></li>
<li class="chapter" data-level="3.2" data-path="model-aggregation.html"><a href="model-aggregation.html#the-quantile-regression-average-ensemble"><i class="fa fa-check"></i><b>3.2</b> The Quantile Regression Average ensemble</a></li>
<li class="chapter" data-level="3.3" data-path="model-aggregation.html"><a href="model-aggregation.html#the-crps-ensemble"><i class="fa fa-check"></i><b>3.3</b> The CRPS ensemble</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="background-data.html"><a href="background-data.html"><i class="fa fa-check"></i><b>4</b> Data and forecasting models</a>
<ul>
<li class="chapter" data-level="4.1" data-path="background-data.html"><a href="background-data.html#introduction-to-the-covid-19-forecast-hub-and-overview-of-the-data"><i class="fa fa-check"></i><b>4.1</b> Introduction to the COVID-19 Forecast Hub and overview of the data</a></li>
<li class="chapter" data-level="4.2" data-path="background-data.html"><a href="background-data.html#an-overview-of-the-different-forecast-models"><i class="fa fa-check"></i><b>4.2</b> An overview of the different forecast models</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="results.html"><a href="results.html"><i class="fa fa-check"></i><b>5</b> Results - evaluation and aggregation of Covid-19 death forecasts</a>
<ul>
<li class="chapter" data-level="5.1" data-path="results.html"><a href="results.html#visualisation"><i class="fa fa-check"></i><b>5.1</b> Forecast visualisation</a></li>
<li class="chapter" data-level="5.2" data-path="results.html"><a href="results.html#summarised-scores"><i class="fa fa-check"></i><b>5.2</b> Summarised scores and overall performance</a></li>
<li class="chapter" data-level="5.3" data-path="results.html"><a href="results.html#relationship"><i class="fa fa-check"></i><b>5.3</b> Examining the relationship between individual metrics</a></li>
<li class="chapter" data-level="5.4" data-path="results.html"><a href="results.html#contributors"><i class="fa fa-check"></i><b>5.4</b> Identifying main contributors to the WIS</a></li>
<li class="chapter" data-level="5.5" data-path="results.html"><a href="results.html#external-drivers"><i class="fa fa-check"></i><b>5.5</b> Identifying external drivers of differences WIS</a></li>
<li class="chapter" data-level="5.6" data-path="results.html"><a href="results.html#model-characteristics"><i class="fa fa-check"></i><b>5.6</b> Understanding model characteristics that drive differences in WIS</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="results.html"><a href="results.html#bias"><i class="fa fa-check"></i><b>5.6.1</b> Bias</a></li>
<li class="chapter" data-level="5.6.2" data-path="results.html"><a href="results.html#coverage"><i class="fa fa-check"></i><b>5.6.2</b> Coverage</a></li>
<li class="chapter" data-level="5.6.3" data-path="results.html"><a href="results.html#pit-histograms"><i class="fa fa-check"></i><b>5.6.3</b> PIT histograms</a></li>
<li class="chapter" data-level="5.6.4" data-path="results.html"><a href="results.html#sharpness"><i class="fa fa-check"></i><b>5.6.4</b> Sharpness</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="results.html"><a href="results.html#ensemble-models"><i class="fa fa-check"></i><b>5.7</b> Specific analysis of ensemble models</a></li>
<li class="chapter" data-level="5.8" data-path="results.html"><a href="results.html#sensitivity"><i class="fa fa-check"></i><b>5.8</b> Sensitivity analysis</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="discussion.html"><a href="discussion.html"><i class="fa fa-check"></i><b>6</b> Summary and discussion</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>A</b> Appendix</a></li>
<li class="divider"></li>
<li><a href="https://github.com/nikosbosse/master_thesis" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><p><img src="logo_university.png" style="width:5in" /></p>
<p><span class="math inline">\(~~~~~\)</span></p>
<p><span class="math inline">\(~~~~~\)</span></p>
<p><strong>Evaluation and Aggregation of Covid-19 Death Forecasts in the United States</strong></p>
<p><span class="math inline">\(~~~~~\)</span></p>
<p><span class="math inline">\(~~~~~\)</span></p></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="model-aggregation" class="section level1" number="3">
<h1><span class="header-section-number">Chapter 3</span> Model aggregation</h1>
<p>Following the discussion of proper scoring rules in Chapter <a href="evaluation.html#evaluation">2</a> we go one step further in this chapter and explore how we can combine individual models to optimal ensembles using these proper scoring rules. This chapter presents two approaches, Quantile Regression Averaging (QRA) that builds upon the weighted interval score and a novel stacking approach that forms an ensemble that minimises the continuous ranked probability score. Prior to discussing these model aggregation approaches, this Chapter provides an intuition for why model ensembles can improve predictive performance and for how different predictive distributions can be combined.</p>
<div id="theoretical-motivation" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Theoretical motivation</h2>
<p>Oftentimes, a single forecasting model is not able to capture the nuances and full complexity of the true data-generating process. Different models have different strengths and weaknesses and often can represent some aspects well that other models may miss. This allows us to increase predictive performance by aggregating individual models.</p>
<p>As an illustrative example, let us consider a number of models that each try to predict one single unknown true value. All models are correct on expectation (i.e. <span class="math inline">\(\mathbb{E}(\hat{y}_k) = y\)</span>), but all exhibit an independent prediction error (i.e. <span class="math inline">\(\hat{y}_k = y + \epsilon_k\)</span>). Every single model will be biased (<span class="math inline">\(\epsilon_k\)</span> has zero probability of being exactly zero, even if <span class="math inline">\(\mathbb{E}(\epsilon_k) = 0\)</span>). The average of all these model predictions, however, will converge to the true value for an increasing number of models. This is, in very simplified terms, the idea behind the mean ensemble. Note that in practice, prediction errors of different models are seldom completely independent, but are instead often correlated, which may reduce the effectiveness of model aggregation. Adding a model to the ensemble of course only makes sense if we indeed believe that its predictions do not deviate systematically from the true values. However, in many circumstances this decision will not be clear cut. Instead, we could decide to give less weight to models that have performed poorly in the past and more weight towards those that performed well. This is the idea behind weighted ensembles.</p>
In the following, we discuss two different ways of combining predictive distributions, the quantile average and the mixture distribution. The quantile average aligns all corresponding quantiles of the predictive distributions and determines the quantiles of the ensemble distribution as a weighted average of the corresponding ensemble member quantiles. We can understand this as a horizontal combination of the cumulative distribution functions (CDF) of the individual predictive distributions. A mixture distribution, on the other hand, can be understood as a vertical combination of the CDFs of the individual ensemble member distribution. It may, however, be more intuitive to think of it as the result of random sampling from the individual ensemble member distributions. The mixture distribution can again be weighted by drawing from the individual distributions with different probabilities. These ideas are illustrated in Figure <a href="model-aggregation.html#fig:average-mixture-example">3.1</a>. In principle, the average seems more appropriate if we there is one single future scenario and we want to optimally predict it. The mixture may be better suited if we believe that our models reflect different possible future scenarios and are uncertain, which of these scenarios will occur.
<div class="figure"><span id="fig:average-mixture-example"></span>
<img src="../visualisation/chapter-4-ensemble/average-mixture-example.png" alt="Two different ways of combining two predictive distributions (based on predictive samples). The left is a mixture distribution (red) generated by taking random samples with equal probability from the two original distributions (green and blue). The right is a quantile average that was generated by taking the pairwise mean of the sorted vectors of the predictive samples from the two distributions. The lower two plots show the same combinations in terms of averages of the cumulative distribution functions. The mixture can be thought of as a vertical combination of CDFs, while the quantile average is a vertical combination." width="95%" />
<p class="caption">
Figure 3.1: Two different ways of combining two predictive distributions (based on predictive samples). The left is a mixture distribution (red) generated by taking random samples with equal probability from the two original distributions (green and blue). The right is a quantile average that was generated by taking the pairwise mean of the sorted vectors of the predictive samples from the two distributions. The lower two plots show the same combinations in terms of averages of the cumulative distribution functions. The mixture can be thought of as a vertical combination of CDFs, while the quantile average is a vertical combination.
</p>
</div>
<p>In the following, we present two different ensemble formation strategies. The Quantile Regression Average (QRA) is an ensemble strategy suited for quantile forecasts that determines optimal weights for a weighted quantile average. The CRPS ensemble works with predictive samples and determines optimal weights for a mixture distribution.</p>
</div>
<div id="the-quantile-regression-average-ensemble" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> The Quantile Regression Average ensemble</h2>
<p>The Quantile Regression Average <span class="citation">(Nowotarski and Weron <a href="#ref-nowotarskiComputingElectricitySpot2015" role="doc-biblioref">2015</a>)</span> is an ensemble strategy build upon the weighted interval score presented in Chapter <a href="evaluation.html#evaluation">2</a>.
Consider a forecast made for observation <span class="math inline">\(i, i = 1, \dots, n\)</span> by model <span class="math inline">\(k, k = 1, \dots, K\)</span> at different quantile levels <span class="math inline">\(\tau \in (0,1)\)</span>. The corresponding quantile prediction for observation <span class="math inline">\(i\)</span> from model <span class="math inline">\(k\)</span> at quantile level <span class="math inline">\(\tau\)</span> is denoted <span class="math inline">\(q_{ik\tau}\)</span>. The ensemble prediction at quantile level <span class="math inline">\(\tau\)</span>, <span class="math inline">\(q_{i, \text{ensemble},\tau}\)</span> is then a weighted average of the corresponding predictive quantiles of the individual models:
<span class="math display">\[q_{i,\text{ensemble}, \tau} = \sum_{k = 1}^K w_k \cdot q_{ik\tau},\]</span>
where <span class="math inline">\(w_k\)</span> is the weight given to model <span class="math inline">\(k\)</span>. The weights are usually constrained to be non-negative and to sum up to one. To get an optimal ensemble, we are looking for the combination of weights that, across all quantile levels <span class="math inline">\(\tau\)</span>, produce an ensemble which minimises the weighted interval score over past observations. The optimisation problem can be denoted as follows <span class="citation">(Tibshirani, Ryan <a href="#ref-ryantibshiraniQuantileStacking2020" role="doc-biblioref">2020</a>)</span>:
<span class="math display">\[\mathop{\text{arg min}}_{w} \sum_{i=1}^n \sum_{\tau} \psi_{_\tau} \bigg(y_i - \sum_{k=1}^K w_k q_{ik\tau} \bigg),\]</span>
where <span class="math inline">\(\psi_{\tau}()\)</span> denotes the so-called pinball loss at quantile level <span class="math inline">\(\tau\)</span>. The pinball loss is defined as
<span class="math display">\[\psi_{\tau}(x) = \max(\tau \cdot x, (\tau-1)\cdot x).\]</span>
The solution to this minimisation problem yields the ensemble that minimises past weighted interval scores. This optimisation problem can be extended in a number of ways. For example, one can estimate different weights for different quantile levels or one can incorporate additional constraints, e.g. that quantiles not cross. The minimisation problem (including the additional constraints) can conveniently be solved using the <code>quantgen</code> package <span class="citation">(Tibshirani <a href="#ref-R-quantgen" role="doc-biblioref">2020</a>)</span>.</p>
</div>
<div id="the-crps-ensemble" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> The CRPS ensemble</h2>
<p>Instead of the weighted interval score, we can also use the CRPS as a basis for an ensemble formation approach. The major conceptual advantage of using CRPS and predictive samples is that we can create a mixture distribution instead of a quantile average. The approach described in the following is a form of stacking (see <span class="citation">Yao et al. (<a href="#ref-yaoUsingStackingAverage2018" role="doc-biblioref">2018</a>)</span>) that is in theory optimal even if the true data-generating distribution is not among the individual ensemble distributions. While many other strategies like Bayesian Model Averaging eventually <span class="citation">(Raftery, Madigan, and Hoeting <a href="#ref-rafteryBayesianModelAveraging1997" role="doc-biblioref">1997</a>; Hoeting et al. <a href="#ref-hoetingBayesianModelAveraging1999" role="doc-biblioref">1999</a>; Raftery et al. <a href="#ref-rafteryUsingBayesianModel2005" role="doc-biblioref">2005</a>)</span> converge to putting all their weights to the single model that is closest to the true data-generating distribution, stacking is able to combine information from all models to form an optimal ensemble.</p>
<p>This CRPS ensembling approach was developed in collaboration with Yuling Yao from the Columbia University in New York and is implemented in the R package <code>stackr</code> <span class="citation">(Bosse et al. <a href="#ref-R-stackr" role="doc-biblioref">2020</a>)</span>. The following method overview is based on work written by Yuling Yao and can also be found in the <code>stackr</code> vignette.</p>
<p>As stated in Equation <a href="evaluation.html#eq:crps">(2.1)</a> in Chapter <a href="evaluation.html#evaluation">2</a>, the CRPS for a predictive distribution with finite first moment and the corresponding true value <span class="math inline">\(y\)</span> is given by
<span class="math display">\[crps(F,y)=\mathbb{E}_X|X-y|- \frac{1}{2}\mathbb{E}_{X,X^\prime}|X-X&#39;|.\]</span>
The notation is slightly altered in comparison to Chapter <a href="evaluation.html#evaluation">2</a> to keep consistency with the <code>stackr</code> vignette and also to avoid having <span class="math inline">\(x\)</span> denote samples as well as observations. The predictive distribution is denoted by <span class="math inline">\(F\)</span> and true observed values are donated by <span class="math inline">\(y\)</span>. Let us assume we have data from <span class="math inline">\(T\)</span> time points <span class="math inline">\(t = 1, \dots, T\)</span> in <span class="math inline">\(R\)</span> regions <span class="math inline">\(r = 1, \dots, R\)</span>. Observations are denoted <span class="math inline">\(y_{tr}\)</span>. Predictive samples are generated from <span class="math inline">\(K\)</span> different models <span class="math inline">\(k = 1, \dots, K\)</span>. For every observation <span class="math inline">\(y_{tr}\)</span> the <span class="math inline">\(S\)</span> predictive samples <span class="math inline">\(s = 1, \dots, S\)</span> are denoted <span class="math inline">\(x_{1ktr}, \dots, x_{Sktr}\)</span>.</p>
<p>Let us first look at the CRPS for one observation and one predictive model before deriving the CRPS of a mixture of all models. Based on the predictive samples, we can compute the CRPS of the <span class="math inline">\(k\)</span>-th model for the observation <span class="math inline">\(y_{tr}\)</span> at time <span class="math inline">\(t\)</span> in region <span class="math inline">\(r\)</span> as
<span class="math display">\[\begin{align*}
 \widehat {\text{crps}}_{ktr} &amp;= \widehat {\text{crps}}(x_{1ktr}, \dots, x_{Sktr},y_{tr}) \\
 &amp;= \frac{1}{S} \sum_{s=1}^S  |x_{sktr}-y_{tr}| - \frac{1}{2S^2} \sum_{s, j=1}^S |x_{sktr}- x_{jktr}|.
\end{align*}\]</span>
Now we want to aggregate predictions from these <span class="math inline">\(K\)</span> models. When the prediction is a mixture of the <span class="math inline">\(K\)</span>
models with weights <span class="math inline">\(w_1, \dots, w_s\)</span>, the CRPS can be expressed as
<span class="math display">\[\begin{align*}
 \widehat {\text{crps}}_{\text{ensemble}, tr} (w_1, \dots, w_K) 
 =&amp; \frac{1}{S} \sum_{k=1}^K w_k  \sum_{s=1}^S |x_{skt}-y_t| \\
 &amp;- \frac{1}{2S^2}  (\sum_{k=1}^K   \sum_{k, k&#39;=1 }^K w_k w_{k&#39;}   \sum_{s, j=1}^S |x_{skt}- x_{jk&#39;t}| ).
\end{align*}\]</span>
The overall CRPS for the mixture of all models for all observations can then simply be obtained by summing up the individual CRPS contributions from the different pairs of observations and predictions over all regions and time points. We can extend this framework by assigning different weights to different time points and regions. This makes sense for example if we want to assign less weight to older observations because we believe they are less characteristic of the current and future dynamics. Similarly, we might want to give more or less weight to certain regions. Mathematically we can introduce a time-varying weight <span class="math inline">\(\lambda_1, \dots, \lambda_T\)</span>, e.g. <span class="math inline">\(\lambda_t = 2-(1-t/T)^2\)</span> to penalize earlier estimates. Likewise we can introduce a region-specific weight <span class="math inline">\(\tau_r\)</span>.</p>
<p>To obtain the optimal CRPS weights we finally solve a quadratic optimisation:
<span class="math display">\[\begin{align*}
 &amp;\min_{w_1, \dots, w_K} \sum_{t=1}^T  \sum_{r=1}^R\lambda_t\tau_r  \widehat {crps}_{\text{ensemble}, tr} (w), \\
  &amp;s.t. ~{0\leq w_1, \dots, w_K \leq 1, \sum_{k=1}^K w_k=1}. 
\end{align*}\]</span>
In <code>stackr</code>, this is implemented using the <code>optimizing</code> function from the <code>rstan</code> <span class="citation">(Guo, Gabry, and Goodrich <a href="#ref-R-rstan" role="doc-biblioref">2020</a>)</span> package. To speed up computation, the terms <span class="math inline">\(\sum_{s=1}^S |x_{skt}-y_{tr}|\)</span>, <span class="math inline">\(\sum_{s, j=1}^S |x_{sktr}- x_{jktr}|\)</span>, and <span class="math inline">\(\sum_{s, j=1}^S |x_{sktr}- x_{jk&#39;tr}|\)</span> are only computed once for all <span class="math inline">\(k, k&#39;\)</span> pairs. Currently, <code>stackr</code> does not yet support different forecast horizons, but instead one horizon has to be chosen to optimise for.</p>
<p>After having obtained the mixture weights we can now obtain the final mixture by drawing samples from the individual member distribution distributions with probability equal to the weight asssigned to the corresponding model. This is implemented in the function <code>mixture_from_samples</code> in <code>stackr</code>. The following code snippet illustrates how a CRPS ensemble can be obtained using <code>stackr</code>:</p>
<p><span class="math inline">\(~\)</span></p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="model-aggregation.html#cb5-1" aria-hidden="true"></a>splitdate &lt;-<span class="st"> </span><span class="kw">as.Date</span>(<span class="st">&quot;2020-03-28&quot;</span>)</span>
<span id="cb5-2"><a href="model-aggregation.html#cb5-2" aria-hidden="true"></a>data &lt;-<span class="st"> </span>data.table<span class="op">::</span><span class="kw">setDT</span>(stackr<span class="op">::</span>example_data)</span>
<span id="cb5-3"><a href="model-aggregation.html#cb5-3" aria-hidden="true"></a><span class="kw">print</span>(data, <span class="dv">3</span>, <span class="dv">3</span>)</span></code></pre></div>
<pre><code>##         geography model sample_nr       date   y_pred    y_obs
##      1:  Tatooine ARIMA         1 2020-03-14 1.719445 1.655068
##      2:  Tatooine ARIMA         2 2020-03-14 1.896555 1.655068
##      3:  Tatooine ARIMA         3 2020-03-14 1.766821 1.655068
##     ---                                                       
## 103998: Coruscant Naive       498 2020-04-08 1.433936 1.543976
## 103999: Coruscant Naive       499 2020-04-08 1.719357 1.543976
## 104000: Coruscant Naive       500 2020-04-08 0.781818 1.543976</code></pre>
<p><span class="math inline">\(~\)</span></p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="model-aggregation.html#cb7-1" aria-hidden="true"></a>traindata &lt;-<span class="st"> </span>data[date <span class="op">&lt;=</span><span class="st"> </span>splitdate]</span>
<span id="cb7-2"><a href="model-aggregation.html#cb7-2" aria-hidden="true"></a>testdata &lt;-<span class="st"> </span>data[date <span class="op">&gt;</span><span class="st"> </span>splitdate]</span>
<span id="cb7-3"><a href="model-aggregation.html#cb7-3" aria-hidden="true"></a></span>
<span id="cb7-4"><a href="model-aggregation.html#cb7-4" aria-hidden="true"></a><span class="co"># Obtain weights based on training data</span></span>
<span id="cb7-5"><a href="model-aggregation.html#cb7-5" aria-hidden="true"></a>weights &lt;-<span class="st"> </span>stackr<span class="op">::</span><span class="kw">crps_weights</span>(traindata)</span>
<span id="cb7-6"><a href="model-aggregation.html#cb7-6" aria-hidden="true"></a></span>
<span id="cb7-7"><a href="model-aggregation.html#cb7-7" aria-hidden="true"></a><span class="co"># create mixture based on predictive samples in the testing data. </span></span>
<span id="cb7-8"><a href="model-aggregation.html#cb7-8" aria-hidden="true"></a>test_mixture &lt;-<span class="st"> </span>stackr<span class="op">::</span><span class="kw">mixture_from_samples</span>(testdata, <span class="dt">weights =</span> weights)</span>
<span id="cb7-9"><a href="model-aggregation.html#cb7-9" aria-hidden="true"></a><span class="kw">print</span>(test_mixture, <span class="dv">3</span>, <span class="dv">3</span>)</span></code></pre></div>
<pre><code>##        geography       date    y_pred sample_nr        model
##     1:  Tatooine 2020-03-29 0.5327176         1 crps_mixture
##     2:  Tatooine 2020-03-29 0.8696770         2 crps_mixture
##     3:  Tatooine 2020-03-29 0.9779118         3 crps_mixture
##    ---                                                      
## 10998: Coruscant 2020-04-08 0.9303099       498 crps_mixture
## 10999: Coruscant 2020-04-08 0.4987309       499 crps_mixture
## 11000: Coruscant 2020-04-08 0.6613497       500 crps_mixture</code></pre>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-R-stackr">
<p>Bosse, Nikos, Yuling Yao, Sam Abbott, and Sebastian Funk. 2020. <em>Stackr: Create Mixture Models from Predictive Samples</em>.</p>
</div>
<div id="ref-R-rstan">
<p>Guo, Jiqiang, Jonah Gabry, and Ben Goodrich. 2020. <em>Rstan: R Interface to Stan</em>. <a href="https://CRAN.R-project.org/package=rstan">https://CRAN.R-project.org/package=rstan</a>.</p>
</div>
<div id="ref-hoetingBayesianModelAveraging1999">
<p>Hoeting, Jennifer A., David Madigan, Adrian E. Raftery, and Chris T. Volinsky. 1999. “Bayesian Model Averaging: A Tutorial.” <em>Statistical Science</em> 14 (4): 382–401.</p>
</div>
<div id="ref-nowotarskiComputingElectricitySpot2015">
<p>Nowotarski, Jakub, and Rafał Weron. 2015. “Computing Electricity Spot Price Prediction Intervals Using Quantile Regression and Forecast Averaging.” <em>Computational Statistics</em> 30 (3): 791–803. <a href="https://doi.org/10.1007/s00180-014-0523-0">https://doi.org/10.1007/s00180-014-0523-0</a>.</p>
</div>
<div id="ref-rafteryUsingBayesianModel2005">
<p>Raftery, Adrian E., Tilmann Gneiting, Fadoua Balabdaoui, and Michael Polakowski. 2005. “Using Bayesian Model Averaging to Calibrate Forecast Ensembles.” <em>Monthly Weather Review</em> 133 (5): 1155–74. <a href="https://doi.org/10.1175/MWR2906.1">https://doi.org/10.1175/MWR2906.1</a>.</p>
</div>
<div id="ref-rafteryBayesianModelAveraging1997">
<p>Raftery, Adrian E., David Madigan, and Jennifer A. Hoeting. 1997. “Bayesian Model Averaging for Linear Regression Models.” <em>Journal of the American Statistical Association</em> 92 (437): 179–91. <a href="https://doi.org/10.1080/01621459.1997.10473615">https://doi.org/10.1080/01621459.1997.10473615</a>.</p>
</div>
<div id="ref-ryantibshiraniQuantileStacking2020">
<p>Tibshirani, Ryan. 2020. “Quantile Stacking.” https://ryantibs.github.io/quantgen/stacking_example.html.</p>
</div>
<div id="ref-R-quantgen">
<p>Tibshirani, Ryan. 2020. <em>Quantgen: Tools for Generalized Quantile Modeling</em>.</p>
</div>
<div id="ref-yaoUsingStackingAverage2018">
<p>Yao, Yuling, Aki Vehtari, Daniel Simpson, and Andrew Gelman. 2018. “Using Stacking to Average Bayesian Predictive Distributions.” <em>Bayesian Analysis</em> 13 (3): 917–1007. <a href="https://doi.org/10.1214/17-BA1091">https://doi.org/10.1214/17-BA1091</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="evaluation.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="background-data.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/nikosbosse/master_thesis/03-ensembling.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["master_thesis.pdf", "master_thesis.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
